{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import re, os, datetime\n",
    "import json\n",
    "from datetime import date\n",
    "pd.set_option('max_colwidth',240)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READ the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtypes = {'original_tweet_id': 'object', 'response_to_status_id': 'object', 'tweet_id': object, 'user_id': 'object'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data_samples/tweets/2017-01-15-klimaat_tweets.csv\", dtype=dtypes, parse_dates = [\"date_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4012 entries, 0 to 4011\n",
      "Data columns (total 19 columns):\n",
      "Unnamed: 0             4012 non-null int64\n",
      "index                  4012 non-null int64\n",
      "tweet_id               4012 non-null object\n",
      "original_tweet_id      2305 non-null object\n",
      "original_tweet_user    2305 non-null object\n",
      "date_time              4012 non-null datetime64[ns]\n",
      "user_id                4012 non-null object\n",
      "username               4012 non-null object\n",
      "followers              4012 non-null int64\n",
      "friends                4012 non-null int64\n",
      "user_description       3544 non-null object\n",
      "statuses               4012 non-null int64\n",
      "text                   4012 non-null object\n",
      "nr_likes               4012 non-null int64\n",
      "users_likes            3994 non-null object\n",
      "nr_RT                  4012 non-null int64\n",
      "entities               4012 non-null object\n",
      "nr_responses           227 non-null float64\n",
      "users_responses        227 non-null object\n",
      "dtypes: datetime64[ns](1), float64(1), int64(7), object(10)\n",
      "memory usage: 595.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARE for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = df.copy().drop(\"Unnamed: 0\", axis = 1).replace(r'', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deduplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = data.drop_duplicates(subset=\"tweet_id\", keep=\"last\") #keep the last occurence of a tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4012"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4012 entries, 0 to 4011\n",
      "Data columns (total 18 columns):\n",
      "index                  4012 non-null int64\n",
      "tweet_id               4012 non-null object\n",
      "original_tweet_id      2305 non-null object\n",
      "original_tweet_user    2305 non-null object\n",
      "date_time              4012 non-null datetime64[ns]\n",
      "user_id                4012 non-null object\n",
      "username               4012 non-null object\n",
      "followers              4012 non-null int64\n",
      "friends                4012 non-null int64\n",
      "user_description       3544 non-null object\n",
      "statuses               4012 non-null int64\n",
      "text                   4012 non-null object\n",
      "nr_likes               4012 non-null int64\n",
      "users_likes            3994 non-null object\n",
      "nr_RT                  4012 non-null int64\n",
      "entities               4012 non-null object\n",
      "nr_responses           227 non-null float64\n",
      "users_responses        227 non-null object\n",
      "dtypes: datetime64[ns](1), float64(1), int64(6), object(10)\n",
      "memory usage: 595.5+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1684"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[~dataset.text.str.contains(\"RT\", na=False)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extraction of *mentions* was added too late and required a dirty solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_mentions(x):\n",
    "      \n",
    "    try:\n",
    "        m = [n.replace(\"screen_name': '\",\"\") for n in re.findall(\"screen_name': '[A-Za-z0-9_]*\", x)]\n",
    "        return \";\".join(m)\n",
    "    except (AttributeError, TypeError):\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset[\"mentions\"] = dataset[\"entities\"].apply(lambda x: extract_mentions(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE a dataset for Gephi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gephi needs nework data in a certain format. This required a lot of cutting and glueing together. See [Gephi reference for csv format](https://gephi.org/users/supported-graph-formats/csv-format/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def splitit(df, column, colname):\n",
    "    \n",
    "    s = df[column].str.split(';').apply(pd.Series, 1).stack().reset_index(level=1, drop=True)\n",
    "    s.name = colname\n",
    "    \n",
    "    #print(s)\n",
    "    return s.replace(r'[?]?', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likes & replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = dataset[[\"username\", \"users_likes\", \"users_responses\"]]\n",
    "n = pd.DataFrame(d[\"username\"])\n",
    "n = n.rename(columns = {\"username\" : \"target\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "likes = splitit(d, \"users_likes\", \"source\")\n",
    "replies = splitit(d, \"users_responses\", \"source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d2 = dataset.loc[dataset[\"original_tweet_user\"].isnull(),[\"username\", \"mentions\"]] #remove retweets\n",
    "m = pd.DataFrame(d2[\"username\"])\n",
    "m = m.rename(columns = {\"username\" : \"source\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mentions = splitit(d2, \"mentions\", \"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rt = dataset[[\"username\", \"original_tweet_user\"]]\n",
    "rt = rt.rename(columns = { \"username\" : \"source\",\n",
    "                            \"original_tweet_user\" : \"target\"})\n",
    "rt = rt.replace(r'', np.nan, regex=True) # NaN instead of empty cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MERGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network = n.join(likes).append(n.join(replies)).append(m.join(mentions)).append(rt).dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REMOVE tweets that have nothing to do with climate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hand picked user names that would have a prominent place in the analysis but their tweets were not on topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eruit = [\"terzaketv\",\"stevencraneTV\",\"rivliv\",\"modernezooi\",\"manjureijmer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network = network[~network.target.isin(eruit)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "edges table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network.to_csv(\"../data_sample/gephi/edges.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nodes table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(dataset[\"username\"].value_counts()).reset_index().to_csv(\"../data_sample/gephi/nodes.csv\",\n",
    "                                                                      header=[\"Id\",\"tweets\"],\n",
    "                                                                      index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use these two sheets in Gephi `Data Laboratory` > `Import Spreadsheet`.<br>Pay attention to the `As table` dropdown. Import first the `edges table` and then the `nodes table` (`tweets` are an integer!).<br>In the `Overview` tab, use the `Force Atlas 2` layout and watch the bubble unfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
